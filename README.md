# ğŸŒ Wikipedia Table Scraper

Welcome to the **Wikipedia Table Scraper** project! This repository contains a Python-based solution for extracting tabular data from Wikipedia pages using web scraping techniques and the Pandas library.

---

## ğŸ“ Project Overview

This project demonstrates how to:
- Scrape tabular data from Wikipedia pages ğŸŒ.
- Use Python ğŸ and Pandas ğŸ“Š for data extraction and manipulation.
- Work with Jupyter Notebooks for interactive development.

With this, you'll gain hands-on experience in data scraping and basic data preprocessing.

---

## ğŸ“– Project Description

### Objectives ğŸ¯
The main objective of this project is to provide a practical example of web scraping by:
1. Extracting tables from Wikipedia pages.
2. Cleaning and structuring the scraped data using Pandas.
3. Saving the processed data into reusable formats like CSV or Excel.

This project is ideal for beginners who are keen to learn the basics of web scraping and working with structured data.

### Features âœ¨
- **Ease of use**: Simple, beginner-friendly code.
- **Data Export**: Save data in CSV format for further analysis.
- **Interactive Notebook**: Step-by-step explanation in a Jupyter Notebook.

---

## ğŸ› ï¸ Tools & Technologies

- **Python** ğŸ: Programming language used for scripting and data manipulation.
- **Pandas** ğŸ“Š: Library for data processing and analysis.
- **Jupyter Notebook** ğŸ““: Interactive environment for coding and documentation.
- **BeautifulSoup** ğŸœ: Library for parsing HTML content.
- **Requests** ğŸŒ: Library to make HTTP requests.

---

## ğŸ”— Acknowledgements

A big thanks to:
- [Wikipedia](https://www.wikipedia.org/) ğŸŒ for providing open and accessible data.
- The developers and maintainers of Python, Pandas, BeautifulSoup, and Requests for their amazing tools.

---

## ğŸš€ Getting Started

1. Clone the repository:
   ```bash
   git clone https://github.com/Rsivamani/wikipedia-table--scraper.git
   ```

2. Install the required Python libraries:
   ```bash
   pip install pandas beautifulsoup4 requests
   ```

3. Open the Jupyter Notebook:
   ```bash
   jupyter notebook Web_scraping_using_py_%26_pandas.ipynb
   ```

Happy Scraping! ğŸ˜„
